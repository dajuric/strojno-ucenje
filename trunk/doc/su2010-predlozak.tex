% Predložak za izradu rada za konferenciju SU2010
% (C) 2010 Jan Šnajder
% KTLab, FER

\documentclass[10pt, a4paper]{article}

\usepackage{su2010}

\usepackage[croatian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings,color}
\usepackage{caption}

\renewcommand{\lstlistingname}{Program}

 \lstset{
 		 language = C,	 
         basicstyle=\small\ttfamily, % Standardschrift
         numbers=left,               % Ort der Zeilennummern
         numberstyle=\tiny,          % Stil der Zeilennummern
         %stepnumber=2,               % Abstand zwischen den Zeilennummern
         numbersep=2pt,              % Abstand der Nummern zum Text
         tabsize=1,                  % Groesse von Tabs
         extendedchars=true,         %
         breaklines=true,            % Zeilen werden Umgebrochen
         lineskip= 0.5pt,	
         keywordstyle=\color{blue},
                frame=b,         
 %        keywordstyle=[1]\textbf,    % Stil der Keywords
 %        keywordstyle=[2]\textbf,    %
 %        keywordstyle=[3]\textbf,    %
 %        keywordstyle=[4]\textbf,   \sqrt{\sqrt{}} %
         stringstyle=\color{white}\ttfamily, % Farbe der String
         showspaces=false,           % Leerzeichen anzeigen ?
         showtabs=false,             % Tabs anzeigen ?
         xleftmargin=5pt,
         framexleftmargin=5pt,
         framexrightmargin=1pt,
         framexbottommargin=1pt,
         %backgroundcolor=\color{lightgray},
         showstringspaces=false      % Leerzeichen in Strings anzeigen ?        
 }

\title{Razrješavanje višeznačnosti riječi}

%VAŽNO: Zakomentirajte sljedeću liniju kada šaljete rad na recenziju
\name{Toni Benussi, Darko Jurić, Krešimir Mišura, Ante Trbojević} 

\address{
Sveučilište u Zagrebu, Fakultet elektrotehnike i računarstva\\
Unska 3, 10000 Zagreb, Hrvatska\\ 
\texttt{\{toni.benussi,darko.juric,kresimir.misura,ante.trbojevic\}@fer.hr},
}
          
         
\abstract{ Ovaj rad razmatra uporabu metoda strojnog učenja u
razrješavanju višeznačnosti riječi \engl{word sense disambiguation}.
Ispituje se uspješnost SVM-a i ansambla naivnih Bayesovih klasifikatora (ANBK)
na jednom uravnoteženom skupu uzoraka i na jednom neuravnoteženom
skupu uzorka, te se ocjenjuje uspješnost tih postupaka na takvim
skupovima. Nenormalizirane riječi teksta (u orginalnom leksičkom obliku) koriste se
kao značajke. Rezultati pokazuju kako SVM ima visoku uspješnost točne klasfikacije, dok
ANBK ima lošu uspješnost na neuravnoteženom skupu. U radu se provodi postupak
pronalaska dobrih značajki za klasifikaciju, tj.~nastoji se
ustanoviti koliko riječi, koje se nalaze u neposrednoj blizini višeznačne riječi u samom tekstu,
uzimati prilikom gradnje klasifikatora i klasifikacije. 
Rezultati pokazuju kako se izlučivanjem 15-ak riječi oko višeznačne riječi postiže
dobra točnost klasifikacije.}

\begin{document}

\maketitleabstract

\section{Uvod}

Riječ kao sastavnica svakog jezika, opisana je leksičkim izrazom i semantičkim značenjem.
Jedan leksički izraz može imati više semantičkih značenja, pri čemu okolni kontekst
sugerira semantičko značenje leksičkog izraza. 
Primjerice leksički izraz \emph{jaguar} ima više semantičkih značenja
(životinja iz porodice mačaka, britanski proizvođač automobila, 
britanska glazbena grupa, parfem), gdje se semantičko značenje riječi \emph{jaguar}
doznaje iz konteksta. Dakle svaka riječ u pisanom tekstu jedinstveno je označena 
leksičkim izrazom i semantičkim značenjem. Upravo iz razloga što odnos 
leksičkog izraza i semantičkog značenja nije injektivan, 
automatizirani postupci kao što je npr.~pretraživanje teksta ili
postavljanje upita nad bazom podataka i sl.~vrlo često korisnicima 
daju neželjene rezultate. Danas lingvistička znanost i računarska znanost 
nastoje pronaći tehnike koje bi dovoljno dobro 
rješavale navedeni problem.

Tehnike strojnog učenja pružaju dovoljno dobru podlogu za realizaciju sustava
koji bi bio sposoban razriješiti višeznačnosti riječi, tj.~identificirati pravo
značenje riječi ovisno o okolnom kontekstu. Stoga su u ovom radu istraženi postupci
strojnog učenja za razrješavanje višeznačnosti riječi, a korišteni postupci su:
stroj s potpornim vektorima (SVM) i ansambl naivnih Bayesovih klasifikatora (ANBK).

Slijedeći problem koji se pojavljuje je kako izlučiti značajke iz konteksta.
U većini slučajeva za značajke se uzima $n$ riječi koje se nalaze u neposrednoj blizini oko višeznačne riječi, gdje je $n \in N$ neka fiksna konstanta. Pogrešno odabran $n$ može pogoršati uspješnost klasifikacije, također intuitivno se može naslutiti kako nije svejedno koliko od tih $n$ riječi se pojavljuje u tekstu s lijeve strane višeznačne riječi, a koliko pak s desne strane.
Upravo ovaj rad nastoji ustanoviti te zavisnosti, te zajedno s priloženim rezultatima provedenih eksperimenata iznosi zaključke kako odabrati kvalitetne značajke.

U idućem poglavlju dan je pregled srodnih radova. Treće poglavlje opisuje bazu
podataka, ekstrahiranje značajki te reprezentiranje uzoraka. Četvrto pogljavlje
daje uvid u provođenja eksperimenta, s kratkim opisom korištenih postupaka
strojnog učenja zajedno s objašnjenjem postupka provođenja validacije i testiranja. U petom
poglavlju izneseni su rezultati eksperimenata te se raspravlja o dobivenim rezultatima.
U zadnjem poglavlju izneseni su zaključci i smjernice za daljnji rad.
\section{Srodni radovi}
Čitajući dostupne radove privukle su nas metode koje
pokušavaju pristupiti tom problemu nama poznatim metodama,
konkretnije pomoću naivnog Bayesovog klasifikatora i SVM-a.
Pristup pomoću stroja sa potpornim vektorima pokazao se dosta
uspješan, ispravno klasificirajući značenje riječi
u skoro 80\% slučajeva, ali kako je opisano u \citep{lee-etc}, da bi se takav
rezultat postigao
potrebno je imati dodatne informacije
o gramatičkim svojstvima teksta. Drugi pristup
pomoću SVM-a je korištenje značenja  riječi
iz leksičke baze WordNet \citep{buscaldi-etc} te usporedba riječi koje opisuju
značenje višeznačne riječi u rječniku sa riječima
iz konteksta u kojem se ta riječ pojavljuje. Nažalost takav pristup
nije se pokazao posebno uspješnim.
Prema radu \citep{pedersen}, naivni Bayesov klasifikator
pokazao se vrlo robusnim rješenjem za ovaj problem.
Njegova ideja temelji se na izradi više klasifikatora s različitim
širinama lijevog i desnog konteksta,
koji bi se koristili za klasifikaciju po sistemu nadglašavanja.
Točnost klasifikacije ovakvog pristupa vrlo je bliska postotku od 80\%.

\section{Opis uzoraka}
Označavanje vlastite baze podataka s višeznačnim riječima izuzetno je
skup proces. Naime za relevantnu klasifikaciju potrebno je barem
oko tisuću uzoraka za jednu višeznačnu riječ, pri tom
označivač za svaki uzorak mora pročitati okolni kontekst i 
shvatiti semantičko značenje riječi te pridodati uzorku oznaku razreda,
što predstavlja dugotrajan proces. Stoga je pribavljena besplatna
baza podataka\footnote{\texttt{http://www.senseval.org/data.html}} s već označenim semantičkim
značenjima za engleske riječi \emph{interest} i \emph{line}. Shodno tome u ovom radu bit će prikazani
postupci razrješavanja višeznačnosti engleskih riječi \emph{interest} i \emph{line}.
Tekstovi u bazi podataka su na engleskom jeziku
i prikupljeni su iz \emph{ACL/DCI Wall Street Journal} novina.

Kao značajke uzorka uzimaju se riječi koje se nalaze unutar prozora konteksta promatranog uzorka.
Prozor konteksta $(l,r)$ \engl{window of context} sastoji se
od $l$ riječi koji se nalaze lijevo od višeznačne riječi (lijevi prozor konteksta) 
i $r$ riječi koji se nalaze desno od višeznačne riječi (desni prozor konteksta), pri čemu se
interpunkcijski i pravopisni znakovi ignoriraju. Sve riječi koje su uključene u prozor konteksta ostavljene su originalnoj leksičkoj formi, tj.~nisu normalizirane, osim što su sva velika
slova pretvorena u mala slova. 
Ova metoda reprezentiranja skupa značajki,
opisana u \citep{pedersen}, varijanta je metode \glqq vreća riječi" \engl{bag-of-words} 
prvi put opisane u \citep{gale-etc}, a razlikuje se po tome što razlikuje 
riječi koje se nalazi lijevo i desno od višeznačne riječi. \mbox{Slika \ref{window_of_context}}
opisuje izlučivanje značajki s definiranim prozorom konteksta $(5,3)$. Naime sve značajke koje
se nalaze unutar tog prozora imati će vrijednost jedan, dok će ostale poprimiti vrijednost nula.

\begin{figure}[!hbtp]
{\small \texttt{     Forward supplies can largely be stored in these same areas, and land forces are best held in reserve on \fbox{our own soil. Drawing a} \emph{line} \fbox{between military aid} and military involvement may be harder, but it can be done if we keep the distinction clearly in mind.}}
\caption{Primjer uzorka višeznačne riječi \emph{line} s prozorom konteksta $(5, 3)$.\label{window_of_context}}
\end{figure}

Baza podataka sadrži 2368 primjera za riječ \emph{interest} i 4148 primjera za riječ \emph{line}.
Primjer je u biti tekst u kojem se nalazi višeznačna riječ, taj tekst smatramo
kontekstom višeznačne riječi. Također svaki primjer, uz tekst, sadrži i atribut koji 
definira semantičko značenje višeznačne riječi u primjeru.

%%Nad bazom podataka napravljena je predobrada podataka tj.~svi zapisi pretvoreni su u XML format
%%u obliku kao što je prikazano na slici \ref{fig:instance_example}, gdje je \texttt{<tag key="division"/>}
%%oznaka koja zamjenjuje višeznačnu riječ \emph{line} i označuje semantičko značenje riječi u tom %%kontekstu.

%%\begin{figure}[!hbtp]
%%{\small \texttt{
%%<sentence>
%%Forward supplies can largely be stored in these same areas , and land forces are best held in reserve %%on our own soil. Drawing a  <tag key="division"/>  between military aid and military involvement may be %%harder , but it can be done if we keep the distinction clearly in mind.
%%</sentence>}}
%%\caption{Primjer zapisa instance za višeznačnu riječ \emph{line}
%%\label{fig:instance_example}}
%\end{figure}

Riječ \emph{interest} ima šest različitih semantičkih značenja (vidi tablicu \ref{tab:interest_distribution}), baš kao i riječ \emph{line},
međutim za riječ \emph{line} izdvojeni su samo oni primjeri kod kojih višeznačna riječ ima
jedno od značenja opisanih u tablici \ref{tab:line_distribution}.
Naime distribucija primjera, po semantičkim značenjima višeznačne riječi, u 
originalnoj bazi podataka za \emph{interest} i \emph{line} je vrlo neujednačen,
stoga je stvoren umjetno uravnotežen skup primjera za \emph{line} kako
bi mogli istražiti koliko koja metoda strojnog učenja
kvalitetno klasificira na neuravnoteženom skupu podataka, 
a koliko na uravnoteženom skupu podataka.

\begin{table}[!hbtp]
\caption{Distribucija primjera po semantičkim značenjima za riječ \emph{interest}}
\label{tab:interest_distribution}
\begin{center}
\begin{tabular}{lll}
\toprule
& Semantičko značenje & Broj primjera \\
\midrule
$I_1$ & interes  	 									& 361\\
$I_2$ & prouzročiti zainteresiranost drugih 			& 11\\
$I_3$ & pokazati zainteresiranost						& 66\\
$I_4$ & prednost ili korist 							& 178\\
$I_5$ & udjel dionica u tvrtci  						& 500\\
$I_6$ & kamate 											& 1252\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\begin{table}[!hbtp]
\caption{Distribucija primjera po semantičkim značenjima za riječ \emph{line}}
\label{tab:line_distribution}
\begin{center}
\begin{tabular}{lll}
\toprule
& Semantičko značenje & Broj primjera \\
\midrule
$L_1$ & tanak oblik, crta							& 373\\
$L_2$ & umjetna podjela, granica 					& 374\\
$L_3$ & formacija ljudi ili stvari					& 349\\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\begin{table*}[!hbtp]
\caption{Broj značajki za riječ \emph{interest} ovisno o veličini prozora konteksta $(l,r)$}
\label{tab:interest_feature_set}
\begin{center}
\begin{tabular}{|c|ccccccccc|}
\hline
$l \setminus r$ & 0 & 1 & 2 & 3 & 4 & 5 & 10 & 25 & 50 \\
\hline
0 &  1 &  219 &  845 &  1489 &  1918 &  2269 &  3387 &  4357 &  4524 \\
1 &  495 &  656 &  1165 &  1726 &  2118 &  2445 &  3509 &  4451 &  4617\\
2 &  1034 &  1151 &  1580 &  2071 &  2423 &  2719 &  3720 &  4624 &  4785\\
3 &  1515 &  1604 &  1980 &  2415 &  2716 &  2988 &  3915 &  4781 &  4940\\
4 &  1944 &  2017 &  2345 &  2733 &  2996 &  3245 &  4125 &  4953 &  5109\\
5 &  2301 &  2364 &  2662 &  3015 &  3261 &  3494 &  4332 &  5129 &  5282\\
10 &  3546 &  3587 &  3817 &  4075 &  4254 &  4442 &  5121 &  5813 &  5955\\
25 &  4906 &  4933 &  5111 &  5313 &  5455 &  5604 &  6168 &  6763 &  6885\\
50 &  5137 &  5162 &  5335 &  5530 &  5665 &  5810 &  6361 &  6938 &  7060\\
\hline
\end{tabular}
\end{center}
\end{table*}

\begin{table*}[!hbtp]
\caption{Broj značajki za riječ \emph{line} ovisno o veličini prozora konteksta $(l,r)$}
\label{tab:line_feature_set}
\begin{center}
\begin{tabular}{|c|ccccccccc|}
\hline
$l \setminus r$ & 0 & 1 & 2 & 3 & 4 & 5 & 10 & 25 & 50 \\
\hline
0  &  1 &  224 &  663 &  1020 &  1299 &  1543 &  2433 &  3395 &  3647\\
1  &  235 &  422 &  825 &  1159 &  1427 &  1657 &  2531 &  3483 &  3731\\
2  &  554 &  691 &  1053 &  1363 &  1617 &  1836 &  2679 &  3609 &  3849\\
3  &  951 &  1058 &  1377 &  1657 &  1898 &  2109 &  2907 &  3803 &  4037\\
4  &  1326 &  1416 &  1703 &  1959 &  2186 &  2384 &  3143 &  4002 &  4231\\
5  &  1683 &  1766 &  2030 &  2267 &  2478 &  2659 &  3378 &  4198 &  4412\\
10 &  3185 &  3244 &  3447 &  3620 &  3783 &  3927 &  4494 &  5166 &  5346\\
25 &  5789 &  5828 &  5970 &  6094 &  6203 &  6296 &  6721 &  7205 &  7359\\
50 &  7046 &  7082 &  7205 &  7315 &  7408 &  7491 &  7854 &  8271 &  8406\\
\hline
\end{tabular}
\end{center}
\end{table*}

Kako je cilj ovog rada ustanoviti koji prozor konteksta $(l,r)$ odabrati
ovisno o algoritmu strojnog učenja (razmatrani su SVM i ANBK)
kako bi klasifikacija bila što uspješnija, stvoreno je 81 skupova uzoraka. Svaki
skup uzoraka dobiven je drugačijim izlučivanjem značajki iz skupa podataka,
pri čemu se skupovi uzoraka razlikuju po veličini prozora konteksta $(l, r)$,
odnosno po kombinaciji koliko je riječi izlučeno s lijeve strane višeznačne riječi (varijabla $l$ u definiciji prozora konteksta), a koliko s desne strane višeznačne riječi (varijabla $r$ u definiciji prozora konteksta). Veličina lijevog prozora konteksta i desnog prozora konteksta, tj.~varijable
$l$ i $r$ poprimaju vrijednosti iz skupa \{0, 1, 2, 3, 4, 5, 10, 25, 50\}. Ne postoji poseban
razlog zašto su odabrane baš te vrijednosti, koje mogu poprimiti varijable $l$ i $r$,
već se slijedila preporuka iz rada \citep{pedersen}, gdje su korištene iste vrijednosti.
Nad svakim od tih skupova uzoraka provedeni su algoritmi SVM i naivni Bayesov (NB) klasifikator, te su izračunate F1 mjere za svaku kombinaciju \emph{skup uzoraka - algoritam}.
Tablica \ref{tab:interest_feature_set} i tablica \ref{tab:line_feature_set} prikazuju ukupan broj izlučenih značajki ovisno o kombinaciju $(l,r)$, tj.~ovisno o skupu uzoraka. Primjećuje
se kako skupovi uzoraka koji su dobiveni izlučivanjem s većim prozorom konteksta imaju
više značajki, što je i očekivano. Naime veći prozor konteksta pohvatati će više 
različitih riječi pa će samim time i ukupan broj značajki biti veći.

\section{Provođenje eksperimenata}
\subsection{Ansambl naivnih Bayesovih klasfikatora (ANBK)}
ANBK funkcionira po principu nadglasavanja, u našem radu ANBK sadrži devet NB klasifikatora.
Predočavanjem uzorka, svaki klasifikator glasa za jedno značenje višeznačne riječi, 
ovisno o \glqq maximum a posteriori" (MAP) vjerojatnosti. Uzorak se 
zatim klasificira u ono semantičko značenje (razred) koje ima najviše glasova.

Odluka koji će NB klasifikatori ući u ANBK donosi se ovisno o rezultatima pojedinačnih
NB klasifikatora na skupu za validaciju.
Za svaki prozor konteksta odgovoran je jedan
NB klasifikator, što čini ukupno 81 NB klasifikatora. 
Nakon provedene validacije odabire se najuspješniji NB klasifikatora
iz svake kategorije, koji zatim ulazi u ANBK. 
Razlikujemo devet kategorija ovisno u veličini prozora konteksta.
Varijable $l$ ili $r$ mogu poprimiti vrijednosti iz raspona \{0, 1, 2, 3, 4, 5, 10, 25, 50\},
pri čemu se razlikuje uski raspon \{0, 1, 2\}, srednji \{3, 4, 5\} i široki \{10, 25, 50\}.
Svaka kombinacija navedenih raspona čini jednu kategoriju. Primjerice
NB klasifikator s prozorom konteksta $(2,3)$ pripada kategoriji \emph{(uski, srednji)}.

Nakon što se iz svake kategorije odabere NB klasifikator koji ima najveću točnost,
pristupa se postupku testiranja ansambla na skupu za testiranje.

\subsection{Stroj s potpornim vektorima (SVM)}
U ovom radu koristi se LibSVM implementacija \mbox{SVM-a}, odnosno C-SVM s linearnom
jezgrenom funkcijom. 
\mbox{C-SVM} je SVM s mekim marginama i ima jedan parametar (cijena koštanja $C$).
Takav SVM omogućuje provlačenje hiperravnine čak i ako problem
nije linearno odvojiv, u takvim slučajevima parametar C određuje koliko će
se kaznati svaki uzorak koji se nalazi s pogrešne strane hiperravnine.

Vrijednost parametra $C$ određuje se validacijom, baš kao
i veličina prozora konteksta.
Postupkom \emph{pretraživanja mreže} \engl{grid search} pronalazi se
optimalna veličina prozora konteksta (raspon mogućih veličina prozora konteksta
isti je kao i za ANBK). Za svaku veličinu prozora konteksta računa se
optimalna vrijednost parametra $C$ i to postupkom \emph{pretraživanja uzorka} \engl{pattern search},
gdje je početna vrijednost $C = 2.5$, a početni korak $2$ (korak se prepolovljava sve dok nije manji od $0.1$).

Testiranje se zatim
provodi na SVM-u s onim parametrima ($C$, veličina prozora konteksta)
koji na skupu za validaciju imaju najmanju pogrešku klasifikacije.

\subsection{Validacija i testiranje}
Validacija i testiranje modela provedeno je unakrsnom provjerom.
Poredak uzoraka u skupu uzoraka nasumično je ispremiješan prije
unakrsne provjere.
Skup uzoraka zatim je podijeljen na pet podskupova, četiri podskupa
služe za učenje modela, dok se posljednji podskup dijeli popola
na još dva podskupa, od kojih jedan služi za validaciju, a drugi za testiranje.
Prije podijele popola, podskup je nasumično ispremiješan, s
namjerom sprječavanja nepravilne distribucije uzoraka u skupu za validaciju
ili skupu za testiranje. Validacija se vrši na dobivenom skupu za validaciju, 
dok skup za testiranje ostaje neaktivan. Nakon završene validacije
slijedi slijedeća iteracija unakrsne provjere, tj.~podskup za validaciju
i testiranje ubacuje se u podskupove za učenje, a jedan od 4 prijašnja podskupa
za učenje postaje skup za validaciju i testiranje. Takvih iterativnih koraka ima ukupno
pet. Valja naglasiti kako se testiranje ne provodi odmah nakon validacije u svakom
iterativnom koraku unakrsne provjere, već se testiranje provodi nakon što je validacija
provedena nad svakim od pet mogućih skupova za validaciju, nakon čega se računaju
optimalni parametri modela, te se tek nakon toga vrši testiranje. 

\begin{lstlisting}[label=lst:Convolution1D,caption= Pseudok\^od implementirane unakrsne provjere]
unakrsnaProvjera(skup uzoraka, algoritam)
{
	lista_skupova = podijeli skup uzorak na pet jednakih dijelova
	za svaki podskup i iz lista_skupova{
		skup_za_ucenje = 4 podskupa iz lista_skupova medu kojima nije i;
		promijesaj i;
		podijeli i na dva dijela
		skup_za_validaciju = prva polovica podijeljenog skupa i
		
		nauci_model(skup_za_ucenje, algoritam)
		validacija(skup_za_validaciju, algoritam)
	}
		
	izracunaj parametre za algoritam
	
	za svaki podskup i iz lista_skupova{
		skup_za_ucenje = 4 podskupa iz lista_skupova medu kojima nije i;
		podijeli i na dva dijela
		skup_za_testiranje = druga polovica podijeljenog skupa i
		
		nauci_model(skup_za_ucenje, algoritam)
		testiraj(skup_za_testiranje, algoritam)
	} 	
}
\end{lstlisting}


Testiranje se provodi baš kao i validacija, tj.~unakrsnom provjerom kroz pet koraka, 
ali je sada skup za validaciju neaktivan, a skup za testiranje aktivan.
Ovakav model učenja, validacije i testiranja odabran je s razlogom, naime
želi se iskoristi što veći skup uzoraka i za validaciju i za testiranje.
Naime ako bi se testiranje vršilo odmah nakon validacije u svakom iterativnom
koraku unakrsne provjere, prilikom testiranja dobiveni rezultati ne bi bili
potpuno objektivni, jer bi rezultati testiranja u tom koraku ovisili
o trenutačnom skupu za validaciju. %TODO (srediti ovo obavezno)

\section{Rezultati}
\subsection{Klasifikacija pomoću ansambla naivnih Bayesovih klasifikatora}
\subsubsection{Rezultati za riječ \emph{interest}} 
Nakon provedene validacije odabire se devet najtočnijih klasifikatora iz
svake kategorije kako bi se dobio ansambl naivnih Bayesovih klasifikatora. 
U tablici \ref{tab:interest_validation_bayes} prikazani su rezultati
validacije (F1 mjere), naivni Bayesovi klasifikatori koji su uključeni u ansambl su oni
s prozorom konteksta: $(1,1)$, $(3,1)$, $(10,1)$,
$(1,3)$, $(4,3)$, $(10,3)$, $(2,25)$, $(5,10)$, $(10,25)$.

Nakon provedenog testiranja F1 mjera ansambla naivnih Bayesovih klasifikatora
iznosi
\begin{equation}
\label{eq:F1_ansambl}
F1_{ANBK(interest)} = 0.7.
\end{equation}
Valja primijetiti kako u ovom
slučaju ansambl od devet naivnih klasifikatora ima manju točnost klasifikacije
od svakog pojedinačnog naivnog Bayesovog klasifikatora od kojih je sastavljen,
iz čega se može zaključiti da ansambl Bayesovih klasfikatora ne mora nužno poboljšati
točnost klasifikacije. Naime u ovom slučaju bilo bi bolje, umjesto ansambla, klasificirati
npr.~s naivnim Bayesovim klasifikatorom s definiranim prozorom konteksta (1, 1), kao
što se može iščitati iz tablice \ref{tab:interest_validation_bayes} njegova F1 mjera iznosi
\begin{equation}
\label{eq:F1_1_1}
F1_{(1,1)} = 0.81.
\end{equation}
Doduše treba uzeti u obzir da je mjera $F1_{ansambl}$ izračunata na skupu za testiranje,
dok je $F1_{(1,1)}$ izračunata na skupu za validaciju, tj.~te dvije mjere nisu
baš usporedive jer nisu dobivene na temelju istih uzoraka.

\begin{table*}[!hbtp]
\caption{F1 mjere Bayesovih klasifikatora dobivene validacijom za riječ \emph{interest}}
\label{tab:interest_validation_bayes}
\begin{center}
\begin{tabular}{|c|ccccccccc|}
\hline
$l \setminus r$ & 0 & 1 & 2 & 3 & 4 & 5 & 10 & 25 & 50 \\
\hline
0  & 0,61 & 0,75 & 0,71 & 0,73 & 0,7  & 0,7  & 0,69 & 0,71 & 0,69  \\
1  & 0,76 & \textbf{0,81} & 0,8  & \textbf{0,78} & 0,76 & 0,75 & 0,72 & 0,73 & 0,71  \\
2  & 0,72 & 0,79 & 0,78 & 0,77 & 0,76 & 0,75 & \textbf{0,74} & 0,74 & 0,72  \\
3  & 0,74 & \textbf{0,78} & 0,77 & 0,76 & 0,76 & 0,77 & 0,75 & 0,73 & 0,72  \\
4  & 0,74 & 0,77 & 0,76 & \textbf{0,78} & 0,76 & 0,77 & 0,75 & 0,73 & 0,73  \\
5  & 0,73 & 0,77 & 0,77 & 0,78 & 0,77 & 0,76 & \textbf{0,76} & 0,74 & 0,74  \\
10 & 0,68 & \textbf{0,73} & 0,73 & \textbf{0,73} & 0,72 & 0,73 & 0,74 & \textbf{0,75} & 0,74  \\
25 & 0,68 & 0,69 & 0,69 & 0,69 & 0,7  & 0,7  & 0,72 & 0,72 & 0,72  \\
5' & 0,66 & 0,68 & 0,68 & 0,69 & 0,69 & 0,68 & 0,7  & 0,72 & 0,72  \\
\hline
\end{tabular}
\end{center}
\end{table*}

\begin{table}[!hbtp]
\caption{Matrica zabune ANBK-a za riječ \emph{interest}}
\label{tab:interest_confusion_bayes}
\begin{center}
\begin{tabular}{|cccccc|c|}
\hline
$I_1$ & $I_2$ & $I_3$ & $I_4$ & $I_5$ & $I_6$ &  \\
\hline
  71  & 0 &  0 &  0 & 28  & 108 &   $I_1$  \\
   1  & 0 &  0 &  0 &  0  &  6  &   $I_2$  \\
   1  & 0 &  0 &  0 &  4  & 37  &   $I_3$  \\
   3  & 0 &  0 &  0 &  7  & 92  &   $I_4$  \\
   0  & 0 &  0 &  0 & 213 & 58  &   $I_5$  \\
   0  & 0 &  0 &  0 &  0  & 556 &   $I_6$  \\
\hline
\end{tabular}
\end{center}
\end{table}

Također ako se promotri tablica \ref{tab:interest_confusion_bayes} lako se uočava
kako niti jedan uzorak nije uspješno klasificiran u razrede $I_2$, $I_3$, $I_4$.
Naime ti razredi imaju barem za red veličine manje uzoraka od najzastupljenijeg razreda $I_6$
u skupu uzoraka (vidi tablicu \ref{tab:interest_distribution}). Ovakvu ne posve
uspješnu, ali prihvatljivu klasifikaciju možemo opravdati neuravnoteženošću uzoraka
između razreda u skupu uzoraka.

Ovakav postupak za riječ \emph{interest} proveden je i u radu \citep{pedersen}, pri
čemu je korištena identična metoda i identični način validacije i testiranja. 
U tom radu točnost\footnote{Kod klasifikacije u više od dvije klasa, točnost je jednaka F1 mjeri.} klasifikacije iznosi $0.88$. 
Razlog zbog čega je naš klasifikator neuspješniji, u odnosu na spomenuti rad, nije nam 
potpuno poznat. Pretpostavljamo da je razlog u različitom pristupu zaglađivanja
apriornih vjerojatnosti s vjerojatnošću nula, tj.~u različitim
implementacijama Bayesovog klasifikatora (u ovom radu korištena
je biblioteka sustava Weka). 

\subsubsection{Rezultati za riječ \emph{line}} 
Rezultati validacije mogu se vidjeti u tablici \ref{tab:line_validation_bayes}.
ANBK je sastavljen od Bayesovih klasifikatora s prozorom konteksta: $(2,2)$,
$(5,2)$, $(10,1)$, $(1,4)$, $(5,4)$, $(10,4)$, $(2,10)$, $(5,10)$ i $(10,10)$.
F1 mjera ANBK-a u ovom slučaju iznosi
\begin{equation}
\label{eq:F1_ansambl_line}
F1_{ANBK(line)} = 0.91,
\end{equation}
što se može smatrati izuzetno uspješnom klasifikacijom. 
Također valja primijetiti kako u ovom slučaju ANBK ima veću točnost
od bilo kojeg pojedinačnog NB klasifikatora, što
se može pravdati uravnoteženošću skupa uzoraka po klasama.
\begin{table*}[!hbtp]
\caption{F1 mjere Bayesovih klasifikatora dobivene validacijom za riječ \emph{line}}
\label{tab:line_validation_bayes}
\begin{center}
\begin{tabular}{|c|ccccccccc|}
\hline
$l \setminus r$ & 0 & 1 & 2 & 3 & 4 & 5 & 10 & 25 & 50 \\
\hline
0  & 0,32  & 0,55  & 0,63  & 0,67  & 0,66  & 0,63  & 0,66  & 0,66  & 0,65 \\  
1  & 0,67  & 0,68  & 0,73  & 0,76  & \textbf{0,8}   & 0,79  & 0,77  & 0,73  & 0,72 \\ 
2  & 0,72  & 0,73  & \textbf{0,79}  & 0,78  & 0,79  & 0,79  & \textbf{0,82}  & 0,77  & 0,76 \\ 
3  &  0,77  & 0,74  & 0,78  & 0,75  & 0,78  & 0,8   & 0,83  & 0,79  & 0,81 \\ 
4  & 0,78  & 0,77  & 0,81  & 0,8   & 0,79  & 0,8   & 0,83  & 0,83  & 0,85 \\ 
5  & 0,8   & 0,81  & \textbf{0,83}  & \textbf{0,83}  & 0,82  & 0,83  & \textbf{0,86}  & 0,84  & 0,85 \\ 
10 & 0,81  & \textbf{0,86}  & 0,83  & 0,86  & \textbf{0,87}  & 0,87  & \textbf{0,9}   & 0,9   & 0,9  \\
25 & 0,76  & 0,77  & 0,81  & 0,81  & 0,82  & 0,84  & 0,85  & 0,83  & 0,83 \\ 
50 & 0,72  & 0,76  & 0,76  & 0,76  & 0,79  & 0,81  & 0,82  & 0,82  & 0,81 \\ 
\hline
\end{tabular}
\end{center}
\end{table*}

\begin{table}[!hbtp]
\caption{Matrica zabune ANBK-a za riječ \emph{line}}
\label{tab:line_confusion_bayes}
\begin{center}
\begin{tabular}{|ccc|c|}
\hline
$L_1$ & $L_2$ & $L_3$ &  \\
\hline
  201 &  8  &  3  &   $L_1$ \\
  11  & 175 &  2  &   $L_2$ \\
  22  & 6   & 122 &   $L_3$ \\
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{Klasifikacija pomoću SVM-a}
\subsubsection{Rezultati za riječ \emph{interest}}
U tablici \ref{tab:interest_validation_svm} nalaze se rezultati validacije.
Za svaki prozor konteksta $(i,j)$ validacijom je izračunat parametar C koji
daje najmanju pogrešku na skupu za validaciju. Onaj SVM kod kojeg kombinacija veličine prozora konteksta i parametra C daje najmanju pogrešku na skupu za validaciju, odabire se za testiranje.
U našem slučaju, kao što se može očitati iz tablice \ref{tab:interest_validation_svm}, to je SVM s prozorom konteksta (5,4) i parametrom $C=0.75$.
\begin{table*}[!hbtp]
\caption{Pogreške i vrijednosti parametara C nakon provedene validacije SVM-a za riječ \emph{interest}}
\label{tab:interest_validation_svm}
\begin{center}
\begin{tabular}{|c|ccccccccc|}
\hline
$l \setminus r$ & 0 & 1 & 2 & 3 & 4 & 5 & 10 & 25 & 50 \\
\hline
0 & 0.46; 2.5 & 0.28; 2.5 & 0.27; 2.5 & 0.26; 0.75 & 0.24; 1.5 & 0.23; 0.625 & 0.24; 0.5 & 0.24; 0.75 & 0.24; 0.375 \\
1 & 0.22; 2.5 & 0.15; 1.75 & 0.14; 0.5 & 0.13; 1.5 & 0.15; 0.75 & 0.14; 0.5 & 0.15; 2.5 & 0.15; 0.5 & 0.15; 0.375 \\
2 & 0.20; 1 & 0.12; 1.25 & 0.12; 0.625 & 0.12; 0.75 & 0.13; 0.75 & 0.12; 1 & 0.12; 0.75 & 0.13; 0.5 & 0.13; 0.5 \\
3 & 0.19; 1 & 0.11; 0.5 & 0.11; 1.5 & 0.11; 0.75 & 0.11; 1.5 & 0.11; 0.5 & 0.11; 0.25 & 0.13; 0.5 & 0.13; 0.5 \\
4 & 0.18; 2 & 0.11; 0.75 & 0.11; 0.75 & 0.11; 2.5 & 0.10; 0.25 & 0.10; 2.5 & 0.10; 0.25 & 0.13; 2.5 & 0.13; 2.5 \\
5 & 0.18; 0.5 & 0.12; 0.5 & 0.12; 2.5 & 0.11; 0.5 & \textbf{0.10; 0.75} & 0.10; 2.5 & 0.10; 0.5 & 0.12; 2.5 & 0.12; 2.5 \\
10 & 0.20; 0.25 & 0.12; 0.25 & 0.12; 0.25 & 0.12; 2.5 & 0.12; 2.5 & 0.12; 2.5 & 0.11; 2.5 & 0.12; 2.5 & 0.12; 2.5 \\
25 & 0.21; 0.5 & 0.14; 0.375 & 0.14; 0.5 & 0.14; 2.5 & 0.13; 2.5 & 0.12; 0.5 & 0.12; 2.5 & 0.13; 2.5 & 0.13; 0.25 \\
50 & 0.20; 0.5 & 0.14; 0.5 & 0.14; 0.25 & 0.14; 2.5 & 0.13; 0.5 & 0.12; 0.25 & 0.12; 2.5 & 0.13; 0.125 & 0.14; 2.5 \\
\hline
\end{tabular}
\end{center}
\end{table*}
\begin{table*}[!hbtp]
\caption{Pogreške i vrijednosti parametara C nakon provedene validacije SVM-a za riječ \emph{line}}
\label{tab:line_validation_svm}
\begin{center}
\begin{tabular}{|c|ccccccccc|}
\hline
$l \setminus r$ & 0 & 1 & 2 & 3 & 4 & 5 & 10 & 25 & 50 \\
\hline
0 & 0.67; 2.5 & 0.40; 2.5 & 0.39; 3 & 0.36; 4.5 & 0.36; 2.75 & 0.36; 1 & 0.35; 0.375 & 0.36; 0.625 & 0.36; 0.5 \\
1 & 0.34; 2.5 & 0.27; 2.5 & 0.27; 1.5 & 0.27; 2 & 0.27; 3 & 0.26; 1.5 & 0.27; 0.375 & 0.27; 0.375 & 0.25; 0.375 \\
2 & 0.25; 1.5 & 0.20; 2.5 & 0.18; 0.5 & 0.19; 2.5 & 0.18; 1 & 0.17; 0.875 & 0.18; 1.375 & 0.19; 1.5 & 0.19; 0.875 \\
3 & 0.22; 6 & 0.18; 3.75 & 0.17; 0.5 & 0.16; 0.25 & 0.18; 4.5 & 0.18; 0.5 & 0.16; 1.5 & 0.16; 0.5 & 0.16; 0.5 \\
4 & 0.23; 2.5 & 0.18; 0.5 & 0.17; 0.5 & 0.16; 0.375 & 0.16; 0.5 & 0.15; 1.5 & 0.14; 0.5 & 0.15; 4.5 & \textbf{0.13; 0.25} \\
5 & 0.21; 0.625 & 0.18; 0.5 & 0.17; 2.5 & 0.16; 0.5 & 0.16; 2.5 & 0.16; 2.5 & 0.16; 2.5 & 0.16; 0.5 & 0.16; 0.5 \\
10 & 0.24; 0.5 & 0.21; 2.5 & 0.19; 2.5 & 0.17; 0.5 & 0.16; 2.5 & 0.15; 2.5 & 0.14; 2.5 & 0.14; 2.5 & 0.15; 2.5 \\
25 & 0.24; 0.375 & 0.20; 0.5 & 0.19; 0.25 & 0.19; 2.5 & 0.19; 2.5 & 0.18; 2.5 & 0.16; 2.5 & 0.16; 2.5 & 0.15; 2.5 \\
50 & 0.27; 2.5 & 0.19; 0.141 & 0.21; 2.5 & 0.21; 0.5 & 0.21; 0.5 & 0.20; 2.5 & 0.18; 2.5 & 0.17; 2.5 & 0.17; 2.5 \\
\hline
\end{tabular}
\end{center}
\end{table*}
Rezultati testiranja vidljivi su u tablici \ref{tab:interest_confusion_svm},
a F1 mjera iznosi
\begin{equation}
\label{eq:f1_svm_interest}
F1_{SVM(interest)} = 0.88
\end{equation}

Ako se ovaj rezultat usporedi s ANBK-om, vidljivo je kako je SVM klasifikator za riječ \emph{interest} podosta uspješniji od ANBK.
Također ako se pomnije promotri tablica \ref{tab:interest_validation_svm}, vidljivo je kako se dobre veličine
prozora konteksta nalaze oko veličine $(5,4)$, 
kako se udaljavamo od te veličine u bilo kojem smjeru, pogreška klasifikacija raste.
Upravo prozor konteksta s veličinom $(5, 4)$ daje najmanju pogrešku,
očito takav prozor konteksta izlučuje najbolje značajke.
Naime manji prozori konteksta (manje vrijednosti varijabli $l$ i $r$) 
ne zahvaćaju karakteristične riječi (one koje rade dobro diskriminiraju između različitih semantičkih značenja) u dovoljnoj mjeri.
Veliki prozor konteksta pak zahvaća i riječi koje ne pridonose diskriminaciji
različitih semantičkih značenja riječi, tj.~zahvaća previše šuma, pa je
pogreška klasifikacije velika, što potvrđuju i rezultati iz tablice \ref{tab:interest_validation_svm}.


\begin{table}[!hbtp]
\caption{Matrica zabune SVM-a za riječ \emph{interest}}
\label{tab:interest_confusion_svm}
\begin{center}
\begin{tabular}{|cccccc|c|}
\hline
$I_1$ & $I_2$ & $I_3$ & $I_4$ & $I_5$ & $I_6$ &  \\
\hline
 164 & 0 &  1 & 12 & 27 &  7 & $I_1$  \\
   0 & 0 &  0 &  5 &  0 &  0 & $I_2$  \\
   6 & 0 & 18 &  7 &  3 &  1 & $I_3$  \\
  13 & 0 & 3  & 63 & 11 &  6 & $I_4$  \\
  16 & 0 & 0  & 4  &204 &  4 & $I_5$  \\
   7 & 0 & 0  & 2  &  3 & 598  &$I_6$  \\
\hline
\end{tabular}
\end{center}
\end{table}
\subsubsection{Rezultati za riječ \emph{line}} 
Na uravnoteženom skupu uzoraka za riječ \emph{line} proveden
je isti postupak kao i za riječ \emph{interest}. 
Rezultati validacije SVM-a vidljivi su u tablici \ref{tab:line_validation_svm}.
Baš kao i za riječ \emph{interest}, nakon validacije odabire se
SVM s onim parametrima koji daju najmanju pogrešku na skupu za validaciju.
Upravo SVM s prozorom konteksta $(4,50)$ i parametrom $C = 0.25$ daje 
najmanju pogrešku na skupu validacije.
Za takav SVM nakon testiranja na skupu za testiranje, dobivena
je matrica zabune prikazana u tablici \ref{tab:line_confusion_svm},
iz koje se može izračunati F1 mjera:
\begin{equation}
\label{eq:f1_svm_line}
F1_{SVM(line)} = 0.84
\end{equation}

\begin{table}[!hbtp]
\caption{Matrica zabune SVM-a za riječ \emph{line}}
\label{tab:line_confusion_svm}
\begin{center}
\begin{tabular}{|ccc|c|}
\hline
$L_1$ & $L_2$ & $L_3$ &  \\
\hline
 170  & 10  & 29 & $L_1$ \\
  15  & 159  & 9 & $L_2$ \\
  23  & 0  & 135 & $L_3$ \\
\hline
\end{tabular}
\end{center}
\end{table}

Valja primijetiti kako su F1 mjere za riječ \emph{interest} (\ref{eq:f1_svm_interest}) i \emph{line} 
(\ref{eq:f1_svm_line}) slične, ne postoji velika razlika kao u slučaju ANBK-a.
Dakle SVM bi bio bolji izbor za razrješavanje vižeznačnosti riječi jer
nije toliko osjetljiv na neuravnotežene i uravnotežene skupove uzoraka
kao što je ANBK.
Također zamjećuje se manja uspješnost SVM-a na uravnoteženom
skupu uzoraka (\emph{line}) u odnosu na neuravnoteženi (\emph{interest}), 
dok je kod ANBK-a obrnuti slučaj.

\section{Zaključak}
Rad rješava problem razrješavanja višeznačnih riječi na postupcima
strojnog učenja. Izneseni su rezultati za SVM postupak i za
ansambl naivnih Bayesovih klasifikatora (ANBK) gdje se odluka donosi
glasanjem devet Bayesovih klasikatora.

Za ovakav nenormaliziran skup podataka, rezultati pokazuju
veću uspješnost SVM algoritma. Eksperimenti su pokazali kako povezivanje više 
NB klasifikatora u ansambl (glasački stroj) ne poboljšava nužno uspješnost klasifikacije.
ANBK se pokazao
izrazito uspješnim na uravnoteženom skupu podataka, dok
na neuravnoteženom skupu podataka daje loše rezultate (velika
pogreška klasifikacije).
Također proveden je eksperiment
koji pronalazi najoptimalniji prozor konteksta za izlučivanje
značajki iz skupa uzoraka. Zaključeno je kako prozor konteksta ne bi trebao
biti niti prevelik, niti premali; svakako ne bi trebao obuhvaćati više od 15-ak riječi, 
u suprotnom uspješnost klasifikacije opada.

U daljnjim istraživanjima svakako bi valjalo provjeriti kako se ANBK i SVM ponašaju na
normaliziranom skupu uzoraka. Naime takav skup bi dao veće težište razlučivim značajkama,
istovremeno bi se smanjio ukupan broj značajki, a time i šum.

\bibliographystyle{su2010}
\bibliography{su2010} 

\end{document}

